Paper Review Log For:  Session 6 (2024/11/20)

Name and (crsid): Sidharrth Nagappan (sn666)

Paper Title and Authors: World Models by David Ha and Jurgen Schmidhuber

-----------------------

1. Paper Summary (<100 words) 
Describe a brief summary (extract essentials).

Far ahead of it's time, World Models combines several generative AI and RL methods that allows agent to learn a low-dimensional representation of their environment (like a dream), and uses this representation to plan and act. Main training is through a variational autoencoder that takes the environment as an input, and uses a mixture density network to predict future states and rewards. It solves OpenAI's Car Racing game and shows the model's visual representation of the racing track and all the decisions it is able to take to navigate the track. 

----------------------------------------------

2. Punch-line of the Paper (<200 words):
What is the significant contribution?
What is the difference from the existing work?

Training an agent to learn and behave entirely within a simulated dream environment is extremely novel. The RL components used in the paper (e.g. visual autoencoders, MDN RNNs) have only been explored independently, so the authors prove in this paper that their amalgamation renders semantically meaningful representations of the environment. It achieves high performance on CarRacing-v0 and VizDoom, while remarkably producing an interpretable representation of the environment. In the age of generative AI, this paper was far ahead of its time, and has crystallised the term 'world model' as a utopian goal for an AI agent in fields like language modelling / robotics.  

The main contribution is proving that developing an internal representation of an environment and learning from it instead of directly interacting with the real environment is more efficient, scalable and "interpretable". 

Existing work is either model-free or use a single model for planning and acting. This paper learns an internal generative environment to use as a testing ground and outperforms these existing methods. It also incorporates uncertainty effectively in temporal dynamics and observation encoding. 

I also loved that the authors had a website for the paper, it was very fun to read. 

3. Any major criticism to the authors (<150 words) ?
Any criticism and suggestions to the authors?
---------------------------------------------

The authors mention that keeping the decision making is offloaded to the VAE and MDN-RNN, and that the controller model can be kept linear. It is interesting to see how the entire setup performs with a more complex controller model, that can map deeper relationships between VAE and MDN-RNN. Even if more complex controllers are harder to optimise, paper can spend some time comparing various controller sizes and their performance. 

The paper came out in 2018, and at the time, there weren't many high capacity models on the market that can store large amounts of memory. With the introduction of transformers and billion-parameter models, it would be interesting to see how this exact setup's semantic representation of the world changes if the VAE and MDN-RNN are replaced by larger models. 

Interesting extensions include "Do Transformer World Models Give Better Policy Gradients?", proposing Actions World Models that better support long-term memory.